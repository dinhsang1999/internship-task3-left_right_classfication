{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9d9f1b1c3e98cd584c7abc6dfa1a222a03734772"
   },
   "outputs": [],
   "source": [
    "height = 224\n",
    "width = height * 1.5\n",
    "dataset_path = \"./preprocess\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/media/ryan/Ryan 1TB/data/fundus-caothang'\n",
    "file_paths = []\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith('jpg') and filename[0] != '.':\n",
    "        file_paths.append(os.path.join(dataset_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2098"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "7f33a3700cc60d61c6b9581a9721589d68fc16a4"
   },
   "outputs": [],
   "source": [
    "file_paths = []\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if 'left' in filename or 'right' in filename:\n",
    "        file_paths.append(os.path.join(dataset_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "89cbb8eb8b01ba873de9bd8d63be7a39d5c2031e"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "3dad3542b836d50fb01c97aa94fad23ad150b241"
   },
   "outputs": [],
   "source": [
    "shuffle(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "55ba1e4da74549117da3e7afd626af1c25e905d5"
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "train_files = file_paths[:int(len(file_paths)*train_ratio)]\n",
    "val_files = file_paths[int(len(file_paths)*train_ratio):int(len(file_paths)*(train_ratio + val_ratio))]\n",
    "test_files = file_paths[int(len(file_paths)*(train_ratio + val_ratio)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c897a82ea28331b893597e84f9814d4d5d0a57d5"
   },
   "outputs": [],
   "source": [
    "class FundusDataset(utils.Dataset):   \n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths_list = image_paths \n",
    "        # List of image paths      \n",
    "        self.labels_list = [] \n",
    "        # List of labels correlated      \n",
    "        self.transform = transform \n",
    "        # Transformation applying to each data piece            \n",
    "        # Run through the folder and get the label of each image inside  \n",
    "        for filename in image_paths:\n",
    "            self.labels_list.append(0 if 'left' in filename else 1)\n",
    "        \n",
    "    def __getitem__(self, index):      \n",
    "        '''      Is called when get DataLoader iterated      '''      \n",
    "        # Get image path with index      \n",
    "        image_path = self.image_paths_list[index]      \n",
    "        # Read image with Pillow library      \n",
    "        image = Image.open(image_path).convert('RGB')      \n",
    "        # Get label      \n",
    "        image_label = self.labels_list[index]      \n",
    "        # Post-transformation apply for image      \n",
    "        if self.transform != None:          \n",
    "            image = self.transform(image)            \n",
    "        return image, image_label, image_path      \n",
    "    def __len__(self):      \n",
    "        return len(self.image_paths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "85eec0d52795c344bf89a1f2840c379d5bbe30e6"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((int(width), int(height))),                                \n",
    "                                transforms.ToTensor(),                                \n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FundusDataset(file_paths, transform)\n",
    "testloader = utils.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b789a661a566b699f09f7ea9bcc8dcfbd0a77c6f"
   },
   "outputs": [],
   "source": [
    "train_dataset = FundusDataset(train_files, transform)\n",
    "trainloader = utils.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "08ca70ef1608ba993925b43ee54b885e533009cb"
   },
   "outputs": [],
   "source": [
    "val_dataset = FundusDataset(val_files, transform)\n",
    "valloader = utils.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "1c6511c7a953086be797bf74cd936822c665c9bc"
   },
   "outputs": [],
   "source": [
    "test_dataset = FundusDataset(test_files, transform)\n",
    "testloader = utils.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "e9588aed56161598a92831d955fc9d8648cbbe9c"
   },
   "outputs": [],
   "source": [
    "class FundusNet(nn.Module):\n",
    "    def __init__(self, is_trained):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet18(pretrained=is_trained)\n",
    "        kernel_count = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(nn.Linear(2560, 2),nn.LogSoftmax(dim=1))\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "f2675bfe0a3a3ab6d6c9583a938816b71b22b149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:    \n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:    \n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "d6644e09dc26ae297f8e476ed3ca0c4445e60c4e"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "model = FundusNet(True)\n",
    "if train_on_gpu:\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "state_dict = torch.load('best_model.pth')\n",
    "model.load_state_dict(state_dict)\n",
    "loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam (model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6848d5a07cca0448c5ae3200f882637030f83c94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100... Validating step 139/139... Loss 0.08697611838579178\n",
      "Epoch: 1/100..  Training Loss: 0.082..  Val Loss: 0.087..  Val Accuracy: 0.980\n",
      "Improve loss of model from 999999999 to 0.08697611838579178\n",
      "Epoch 2/100... Validating step 139/139... Loss 0.05596523731946945\n",
      "Epoch: 2/100..  Training Loss: 0.059..  Val Loss: 0.056..  Val Accuracy: 0.985\n",
      "Improve loss of model from 0.08697611838579178 to 0.05596523731946945\n",
      "Epoch 3/100... Validating step 139/139... Loss 0.050387900322675705\n",
      "Epoch: 3/100..  Training Loss: 0.052..  Val Loss: 0.050..  Val Accuracy: 0.986\n",
      "Improve loss of model from 0.05596523731946945 to 0.050387900322675705\n",
      "Epoch 4/100... Validating step 139/139... Loss 0.04691079631447792\n",
      "Epoch: 4/100..  Training Loss: 0.048..  Val Loss: 0.047..  Val Accuracy: 0.988\n",
      "Improve loss of model from 0.050387900322675705 to 0.04691079631447792\n",
      "Epoch 5/100... Validating step 139/139... Loss 0.045561980456113815\n",
      "Epoch: 5/100..  Training Loss: 0.046..  Val Loss: 0.046..  Val Accuracy: 0.989\n",
      "Improve loss of model from 0.04691079631447792 to 0.045561980456113815\n",
      "Epoch 6/100... Validating step 139/139... Loss 0.048575591295957565\n",
      "Epoch: 6/100..  Training Loss: 0.044..  Val Loss: 0.049..  Val Accuracy: 0.987\n",
      "Epoch 7/100... Validating step 139/139... Loss 0.05019161105155945\n",
      "Epoch: 7/100..  Training Loss: 0.042..  Val Loss: 0.050..  Val Accuracy: 0.986\n",
      "Epoch 8/100... Validating step 139/139... Loss 0.04382586106657982\n",
      "Epoch: 8/100..  Training Loss: 0.041..  Val Loss: 0.044..  Val Accuracy: 0.989\n",
      "Improve loss of model from 0.045561980456113815 to 0.04382586106657982\n",
      "Epoch 9/100... Validating step 139/139... Loss 0.0510668009519577\n",
      "Epoch: 9/100..  Training Loss: 0.038..  Val Loss: 0.051..  Val Accuracy: 0.986\n",
      "Epoch 10/100... Validating step 139/139... Loss 0.04763232171535492\n",
      "Epoch: 10/100..  Training Loss: 0.036..  Val Loss: 0.048..  Val Accuracy: 0.987\n",
      "Epoch 11/100... Training step 981/1109... Loss 0.03204028498168719"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "epochs = 100\n",
    "train_losses, val_losses = [], []\n",
    "best_loss = 999999999\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for step, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        if train_on_gpu:               \n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        ps = model(images)            \n",
    "        loss_val = loss(ps, labels)\n",
    "        loss_val.backward()            \n",
    "        optimizer.step()\n",
    "        running_loss += loss_val.item()\n",
    "        sys.stdout.write(f\"\\rEpoch {e+1}/{epochs}... Training step {step+1}/{len(trainloader)}... Loss {running_loss/(step+1)}\")\n",
    "    else:\n",
    "        val_loss = 0            \n",
    "        accuracy = 0\n",
    "        with torch.no_grad():                \n",
    "            for step, (images, labels) in enumerate(valloader):                    \n",
    "                if train_on_gpu:                       \n",
    "                    images, labels = images.cuda(), labels.cuda()                    \n",
    "                log_ps = model(images)\n",
    "                val_loss += loss(log_ps, labels)\n",
    "                ps = torch.exp(log_ps)                    \n",
    "                top_p, top_class = ps.topk(1, dim=1)                    \n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                sys.stdout.write(f\"\\rEpoch {e+1}/{epochs}... Validating step {step+1}/{len(valloader)}... Loss {val_loss/(step+1)}\")\n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        val_losses.append(val_loss/len(valloader))\n",
    "        scheduler.step(val_loss/len(valloader))\n",
    "        print(\"\\nEpoch: {}/{}.. \".format(e+1, epochs),                  \n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),                  \n",
    "              \"Val Loss: {:.3f}.. \".format(val_loss/len(valloader)),                  \n",
    "              \"Val Accuracy: {:.3f}\".format(accuracy/len(valloader)))\n",
    "        if best_loss > val_loss/len(valloader):\n",
    "            print(\"Improve loss of model from {} to {}\".format(best_loss, val_loss/len(valloader)))\n",
    "            best_loss = val_loss/len(valloader)\n",
    "            torch.save(model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7d1573deec83d0181010bc402b9651ff2b69269"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "bca3fdf2104f5749d3b786af2ecfca2a0eb3b3db"
   },
   "outputs": [],
   "source": [
    "groundtruths = []\n",
    "predictions = []\n",
    "probabilities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): FundusNet(\n",
       "    (resnet): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=2560, out_features=2, bias=True)\n",
       "        (1): LogSoftmax()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 33/33"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "accuracy = 0\n",
    "predictions = {}\n",
    "with torch.no_grad():\n",
    "    for step, (images, labels, paths) in enumerate(testloader):\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        path_lists = list(paths)\n",
    "        for path in path_lists:\n",
    "            predictions[path] = {}\n",
    "        #for idx,label in enumerate(labels.cpu().view(-1).numpy().tolist()):\n",
    "            #predictions[path_lists[idx]]['gt'] = label\n",
    "        output = model.forward(images)\n",
    "        ps = torch.exp(output)\n",
    "        for idx, prob in enumerate(ps.cpu().view(-1,2).numpy().tolist()):\n",
    "            predictions[path_lists[idx]]['prob'] = prob\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        for idx,pred in enumerate(top_class.cpu().view(-1).numpy().tolist()):\n",
    "            predictions[path_lists[idx]]['pred'] = pred\n",
    "        #equals = top_class == labels.view(*top_class.shape)\n",
    "        #accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        sys.stdout.write(f\"\\rStep {step+1}/{len(testloader)}\")\n",
    "#print(f\"\\nTest accuracy: {accuracy/len(testloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#data = pd.DataFrame({'image': [], 'prob_left':[], 'prob_right': [], 'prediction': [],'groundtruth': []})\n",
    "data = pd.DataFrame({'image': [], 'prob_left':[], 'prob_right': [], 'prediction': []})#,'groundtruth': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-49a7f989312c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prob_left'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prob_right'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prediction'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'groundtruth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gt'"
     ]
    }
   ],
   "source": [
    "for file, val in predictions.items():\n",
    "    row = {'image': file, 'prob_left': val['prob'][0], 'prob_right': val['prob'][1], 'prediction': val['pred'],'groundtruth': val['gt']}\n",
    "    data = data.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>prob_left</th>\n",
       "      <th>prob_right</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/media/ryan/Ryan 1TB/data/fundus-caothang/2016...</td>\n",
       "      <td>0.091106</td>\n",
       "      <td>0.908894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/media/ryan/Ryan 1TB/data/fundus-caothang/2016...</td>\n",
       "      <td>0.356699</td>\n",
       "      <td>0.643301</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/media/ryan/Ryan 1TB/data/fundus-caothang/2016...</td>\n",
       "      <td>0.775021</td>\n",
       "      <td>0.224979</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/media/ryan/Ryan 1TB/data/fundus-caothang/2016...</td>\n",
       "      <td>0.618606</td>\n",
       "      <td>0.381394</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/media/ryan/Ryan 1TB/data/fundus-caothang/2016...</td>\n",
       "      <td>0.998531</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  prob_left  prob_right  \\\n",
       "0  /media/ryan/Ryan 1TB/data/fundus-caothang/2016...   0.091106    0.908894   \n",
       "1  /media/ryan/Ryan 1TB/data/fundus-caothang/2016...   0.356699    0.643301   \n",
       "2  /media/ryan/Ryan 1TB/data/fundus-caothang/2016...   0.775021    0.224979   \n",
       "3  /media/ryan/Ryan 1TB/data/fundus-caothang/2016...   0.618606    0.381394   \n",
       "4  /media/ryan/Ryan 1TB/data/fundus-caothang/2016...   0.998531    0.001468   \n",
       "\n",
       "   prediction  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file, val in predictions.items():\n",
    "    row = {'image': file, 'prob_left': val['prob'][0], 'prob_right': val['prob'][1], 'prediction': val['pred']}\n",
    "    data = data.append(row, ignore_index=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"caothang-result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>prob_left</th>\n",
       "      <th>prob_right</th>\n",
       "      <th>prediction</th>\n",
       "      <th>groundtruth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./preprocess/33747_left.jpeg</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./preprocess/37756_left.jpeg</td>\n",
       "      <td>0.981119</td>\n",
       "      <td>0.018881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./preprocess/17342_left.jpeg</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./preprocess/28308_right.jpeg</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.994632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./preprocess/14190_right.jpeg</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.997911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image  prob_left  prob_right  prediction  \\\n",
       "0   ./preprocess/33747_left.jpeg   0.999980    0.000020         0.0   \n",
       "1   ./preprocess/37756_left.jpeg   0.981119    0.018881         0.0   \n",
       "2   ./preprocess/17342_left.jpeg   0.999998    0.000003         0.0   \n",
       "3  ./preprocess/28308_right.jpeg   0.005368    0.994632         1.0   \n",
       "4  ./preprocess/14190_right.jpeg   0.002089    0.997911         1.0   \n",
       "\n",
       "   groundtruth  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          1.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
